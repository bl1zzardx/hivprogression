{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T11:10:09.508603Z","iopub.execute_input":"2022-05-10T11:10:09.508990Z","iopub.status.idle":"2022-05-10T11:10:09.542082Z","shell.execute_reply.started":"2022-05-10T11:10:09.508899Z","shell.execute_reply":"2022-05-10T11:10:09.541395Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Preliminaries","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils import data\nimport wandb\nwandb.init(project=\"HIV_kaggle\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:10:09.543377Z","iopub.execute_input":"2022-05-10T11:10:09.544064Z","iopub.status.idle":"2022-05-10T11:13:42.403673Z","shell.execute_reply.started":"2022-05-10T11:10:09.544015Z","shell.execute_reply":"2022-05-10T11:13:42.402650Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Parse and look at first 5 rows","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/hivprogression/training_data.csv')\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:42.405902Z","iopub.execute_input":"2022-05-10T11:13:42.406280Z","iopub.status.idle":"2022-05-10T11:13:43.368004Z","shell.execute_reply.started":"2022-05-10T11:13:42.406248Z","shell.execute_reply":"2022-05-10T11:13:43.367271Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"n_train = train_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:43.369227Z","iopub.execute_input":"2022-05-10T11:13:43.369576Z","iopub.status.idle":"2022-05-10T11:13:44.271548Z","shell.execute_reply.started":"2022-05-10T11:13:43.369547Z","shell.execute_reply":"2022-05-10T11:13:44.270572Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"We have to remove the first two columns","metadata":{}},{"cell_type":"code","source":"all_features = train_data.iloc[:, 2:]\n# one can assume if Seqs are not present it is a bad sign for survival\nall_features[\"PR SeqNan\"] = all_features[\"PR Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\nall_features[\"RT SeqNan\"] = all_features[\"RT Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\nnumeric_features = all_features.dtypes[(all_features.dtypes != 'object') & (all_features.dtypes != 'bool')].index\nmean_numerical_features = all_features[numeric_features].mean()\nstd_numerical_features = all_features[numeric_features].std()\nall_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / x.std() + 1e-4)\nvt_mean = all_features[\"VL-t0\"].mean()\ncd4_mean = all_features[\"CD4-t0\"].mean()\nall_features[\"VL-t0\"] = all_features[\"VL-t0\"].fillna(vt_mean)\nall_features[\"CD4-t0\"] = all_features[\"CD4-t0\"].fillna(cd4_mean)\nall_features.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:44.274285Z","iopub.execute_input":"2022-05-10T11:13:44.274531Z","iopub.status.idle":"2022-05-10T11:13:45.104694Z","shell.execute_reply.started":"2022-05-10T11:13:44.274504Z","shell.execute_reply":"2022-05-10T11:13:45.103813Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize and Vocab","metadata":{}},{"cell_type":"code","source":"import collections\n\ndef tokenize(seqs):\n    return [tokenize_line(seq) for seq in seqs]\n\ndef tokenize_line(seq):\n    if not pd.isna(seq):\n        return list(seq)\n    return []\n\nclass Vocab:\n    def __init__(self, tokens):\n        counter = count_corpus(tokens)\n        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                   reverse=True)\n        self.idx_to_token = ['<unk>']\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n        for token, freq in self._token_freqs:\n            if token not in self.token_to_idx:\n                self.idx_to_token.append(token)\n                self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\n    @property\n    def unk(self): \n        return 0\n\n    @property\n    def token_freqs(self):\n        return self._token_freqs\n\ndef count_corpus(tokens):\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)\n\ntokens_pr = tokenize(all_features[\"PR Seq\"].values)\nvocab_pr = Vocab(tokens_pr)\nlist(vocab_pr.token_to_idx.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:45.106195Z","iopub.execute_input":"2022-05-10T11:13:45.106531Z","iopub.status.idle":"2022-05-10T11:13:45.866642Z","shell.execute_reply.started":"2022-05-10T11:13:45.106489Z","shell.execute_reply":"2022-05-10T11:13:45.865787Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"all_features[\"PR Seq\"] = all_features[\"PR Seq\"].apply(lambda x: vocab_pr[tokenize_line(x)])\nall_features[\"PR Seq\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:45.868797Z","iopub.execute_input":"2022-05-10T11:13:45.869571Z","iopub.status.idle":"2022-05-10T11:13:46.805658Z","shell.execute_reply.started":"2022-05-10T11:13:45.869533Z","shell.execute_reply":"2022-05-10T11:13:46.804917Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokens_rt = tokenize(all_features[\"RT Seq\"].values)\nvocab_rt = Vocab(tokens_rt)\nlist(vocab_rt.token_to_idx.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:46.807253Z","iopub.execute_input":"2022-05-10T11:13:46.808121Z","iopub.status.idle":"2022-05-10T11:13:47.647763Z","shell.execute_reply.started":"2022-05-10T11:13:46.808045Z","shell.execute_reply":"2022-05-10T11:13:47.646909Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"all_features[\"RT Seq\"] = all_features[\"RT Seq\"].apply(lambda x: vocab_rt[tokenize_line(x)])\nall_features[\"RT Seq\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:47.648879Z","iopub.execute_input":"2022-05-10T11:13:47.649559Z","iopub.status.idle":"2022-05-10T11:13:49.335091Z","shell.execute_reply.started":"2022-05-10T11:13:47.649523Z","shell.execute_reply":"2022-05-10T11:13:49.334255Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"training_size = int(0.7 * n_train)\nnb_iterations = 10\nfor j in range(nb_iterations):\n    for i, data in enumerate(all_features.values):\n        if i >= training_size:\n            break\n        # TODO","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:49.336210Z","iopub.execute_input":"2022-05-10T11:13:49.337058Z","iopub.status.idle":"2022-05-10T11:13:50.175027Z","shell.execute_reply.started":"2022-05-10T11:13:49.337020Z","shell.execute_reply":"2022-05-10T11:13:50.173889Z"},"trusted":true},"execution_count":10,"outputs":[]}]}