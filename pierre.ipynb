{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T20:23:15.974929Z","iopub.execute_input":"2022-05-10T20:23:15.975322Z","iopub.status.idle":"2022-05-10T20:23:16.479879Z","shell.execute_reply.started":"2022-05-10T20:23:15.975283Z","shell.execute_reply":"2022-05-10T20:23:16.478810Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Preliminaries","metadata":{}},{"cell_type":"code","source":"np.random.seed(0)\nrandom.seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:16.482335Z","iopub.execute_input":"2022-05-10T20:23:16.482890Z","iopub.status.idle":"2022-05-10T20:23:16.775197Z","shell.execute_reply.started":"2022-05-10T20:23:16.482834Z","shell.execute_reply":"2022-05-10T20:23:16.773642Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, Tensor\nfrom torch import optim\nfrom torch.utils import data\nimport wandb\nwandb.init(project=\"HIV_kaggle\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:16.776827Z","iopub.execute_input":"2022-05-10T20:23:16.777109Z","iopub.status.idle":"2022-05-10T20:23:28.617816Z","shell.execute_reply.started":"2022-05-10T20:23:16.777079Z","shell.execute_reply":"2022-05-10T20:23:28.616970Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Parse and look at first 5 rows","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/hivprogression/training_data.csv')\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:28.620697Z","iopub.execute_input":"2022-05-10T20:23:28.621654Z","iopub.status.idle":"2022-05-10T20:23:28.660476Z","shell.execute_reply.started":"2022-05-10T20:23:28.621606Z","shell.execute_reply":"2022-05-10T20:23:28.659528Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"labels = torch.tensor(train_data[\"Resp\"].values, dtype=torch.float)\nn_labels = labels.shape[0]\nn_labels","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:28.662453Z","iopub.execute_input":"2022-05-10T20:23:28.662828Z","iopub.status.idle":"2022-05-10T20:23:28.670603Z","shell.execute_reply.started":"2022-05-10T20:23:28.662780Z","shell.execute_reply":"2022-05-10T20:23:28.669929Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"n_train = train_data.shape[0]\nn_train","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:28.671714Z","iopub.execute_input":"2022-05-10T20:23:28.672421Z","iopub.status.idle":"2022-05-10T20:23:28.688520Z","shell.execute_reply.started":"2022-05-10T20:23:28.672381Z","shell.execute_reply":"2022-05-10T20:23:28.687797Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"We have to remove the first two columns","metadata":{}},{"cell_type":"code","source":"\nall_features = train_data.iloc[:, 2:]\n# one can assume if Seqs are not present it is a bad sign for survival\nall_features[\"PR SeqNan\"] = all_features[\"PR Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\nall_features[\"RT SeqNan\"] = all_features[\"RT Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\nnumeric_features = all_features.dtypes[(all_features.dtypes != 'object') & (all_features.dtypes != 'bool')].index\nmean_numerical_features = all_features[numeric_features].mean()\nstd_numerical_features = all_features[numeric_features].std()\nall_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / x.std() + 1e-4)\nvt_mean = all_features[\"VL-t0\"].mean()\ncd4_mean = all_features[\"CD4-t0\"].mean()\nall_features[\"VL-t0\"] = all_features[\"VL-t0\"].fillna(vt_mean)\nall_features[\"CD4-t0\"] = all_features[\"CD4-t0\"].fillna(cd4_mean)\nall_features.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:28.689800Z","iopub.execute_input":"2022-05-10T20:23:28.690068Z","iopub.status.idle":"2022-05-10T20:23:28.729195Z","shell.execute_reply.started":"2022-05-10T20:23:28.690039Z","shell.execute_reply":"2022-05-10T20:23:28.728033Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def f_comma(my_str, group=3, char=','):\n    my_str = str(my_str)\n    return char.join(my_str[i:i+group] for i in range(0, len(my_str), group))\n\nfor index, row in all_features.iterrows():\n    all_features['PR Seq'] = all_features['PR Seq'].replace([row['PR Seq']], f_comma(row['PR Seq']))\n    all_features['RT Seq'] = all_features['RT Seq'].replace([row['RT Seq']], f_comma(row['RT Seq']))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:28.730487Z","iopub.execute_input":"2022-05-10T20:23:28.730907Z","iopub.status.idle":"2022-05-10T20:23:30.314752Z","shell.execute_reply.started":"2022-05-10T20:23:28.730869Z","shell.execute_reply":"2022-05-10T20:23:30.313392Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize and Vocab","metadata":{}},{"cell_type":"code","source":"import collections\n\ndef tokenize(seqs):\n    return [tokenize_line(seq) for seq in seqs]\n\ndef tokenize_line(seq):\n    if not pd.isna(seq):\n        return list(seq.split(','))\n    return []\n\nclass Vocab:\n    def __init__(self, tokens):\n        counter = count_corpus(tokens)\n        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                   reverse=True)\n        self.idx_to_token = ['<unk>']\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n        for token, freq in self._token_freqs:\n            if token not in self.token_to_idx:\n                self.idx_to_token.append(token)\n                self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\n    @property\n    def unk(self): \n        return 0\n\n    @property\n    def token_freqs(self):\n        return self._token_freqs\n\ndef count_corpus(tokens):\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)\n\ntokens_pr = tokenize(all_features[\"PR Seq\"].values)\nvocab_pr = Vocab(tokens_pr)\n#list(vocab_pr.token_to_idx.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.318128Z","iopub.execute_input":"2022-05-10T20:23:30.318598Z","iopub.status.idle":"2022-05-10T20:23:30.371869Z","shell.execute_reply.started":"2022-05-10T20:23:30.318548Z","shell.execute_reply":"2022-05-10T20:23:30.371093Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"all_features[\"PR Seq\"] = all_features[\"PR Seq\"].apply(lambda x: vocab_pr[tokenize_line(x)])\nall_features[\"PR Seq\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.373443Z","iopub.execute_input":"2022-05-10T20:23:30.374315Z","iopub.status.idle":"2022-05-10T20:23:30.466775Z","shell.execute_reply.started":"2022-05-10T20:23:30.374257Z","shell.execute_reply":"2022-05-10T20:23:30.465523Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"tokens_rt = tokenize(all_features[\"RT Seq\"].values)\nvocab_rt = Vocab(tokens_rt)\n#list(vocab_rt.token_to_idx.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.468472Z","iopub.execute_input":"2022-05-10T20:23:30.468755Z","iopub.status.idle":"2022-05-10T20:23:30.585348Z","shell.execute_reply.started":"2022-05-10T20:23:30.468723Z","shell.execute_reply":"2022-05-10T20:23:30.584640Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"all_features[\"RT Seq\"] = all_features[\"RT Seq\"].apply(lambda x: vocab_rt[tokenize_line(x)])\nall_features[\"RT Seq\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.586594Z","iopub.execute_input":"2022-05-10T20:23:30.587024Z","iopub.status.idle":"2022-05-10T20:23:30.852804Z","shell.execute_reply.started":"2022-05-10T20:23:30.586989Z","shell.execute_reply":"2022-05-10T20:23:30.851774Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"import math\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\n\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x: Tensor) -> Tensor:\n        x = x + self.pe[:x.size(0)]\n        return self.dropout(x)\n\nclass TransformerModel(nn.Module):\n\n    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n                 nlayers: int, dropout: float = 0.5):\n        super().__init__()\n        self.pos_encoder = PositionalEncoding(d_model, dropout)\n        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n        self.encoder = nn.Embedding(ntoken, d_model)\n        self.d_model = d_model\n        self.decoder = nn.Linear(d_model, 1)\n        self.init_weights()\n\n    def init_weights(self) -> None:\n        initrange = 0.1\n        self.encoder.weight.data.uniform_(-initrange, initrange)\n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n        src = self.encoder(src) * math.sqrt(self.d_model)\n        src = self.pos_encoder(src)\n        output = self.transformer_encoder(src, src_mask)[:, 0]\n        output = self.decoder(output)\n        return output\n    \ndef generate_square_subsequent_mask(sz: int) -> Tensor:\n    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.854494Z","iopub.execute_input":"2022-05-10T20:23:30.855349Z","iopub.status.idle":"2022-05-10T20:23:30.873485Z","shell.execute_reply.started":"2022-05-10T20:23:30.855292Z","shell.execute_reply":"2022-05-10T20:23:30.872183Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Performance optimization => batching","metadata":{}},{"cell_type":"markdown","source":"Padding text inputs","metadata":{}},{"cell_type":"code","source":"def padding_input(seqs):\n    # determine max length\n    max_length = 0\n    for seq in seqs:\n        max_length = max(max_length, len(seq))\n    result = torch.zeros((seqs.shape[0], max_length), dtype=int)\n    for i in range(seqs.shape[0]):\n        for j in range(len(seqs[i])):\n            result[i][j] = seqs[i][j]\n    return result, max_length","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.874782Z","iopub.execute_input":"2022-05-10T20:23:30.875080Z","iopub.status.idle":"2022-05-10T20:23:30.894156Z","shell.execute_reply.started":"2022-05-10T20:23:30.875037Z","shell.execute_reply":"2022-05-10T20:23:30.893027Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"pr_data, pr_length = padding_input(all_features[\"PR Seq\"].values)\nrt_data, rt_length = padding_input(all_features[\"RT Seq\"].values)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:30.896210Z","iopub.execute_input":"2022-05-10T20:23:30.896558Z","iopub.status.idle":"2022-05-10T20:23:32.660758Z","shell.execute_reply.started":"2022-05-10T20:23:30.896511Z","shell.execute_reply":"2022-05-10T20:23:32.659587Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Dataset and DataLoaders","metadata":{}},{"cell_type":"code","source":"training_size = int(0.7 * n_train)\ntrain_indexes = np.random.choice(n_train, training_size)\nnumerical_features = torch.tensor(all_features.iloc[:, 2:].astype('float').values, dtype=torch.float32)\ndataset_features = torch.utils.data.TensorDataset(numerical_features, labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:32.697634Z","iopub.execute_input":"2022-05-10T20:23:32.697964Z","iopub.status.idle":"2022-05-10T20:23:32.706054Z","shell.execute_reply.started":"2022-05-10T20:23:32.697915Z","shell.execute_reply":"2022-05-10T20:23:32.705019Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# TO FIX : SPLITTING DATASET","metadata":{}},{"cell_type":"code","source":"selected_index = torch.zeros((n_train, ), dtype=bool)\nselected_index[train_indexes] = True\nloader_features_train = torch.utils.data.DataLoader(dataset_features, batch_size=32, shuffle=False)\nloader_pr_train = torch.utils.data.DataLoader(pr_data, batch_size=32, shuffle=False)\nloader_rt_train = torch.utils.data.DataLoader(rt_data, batch_size=32, shuffle=False)\nselected_index = torch.ones((n_train, ), dtype=bool)\nselected_index[train_indexes] = False","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:32.707396Z","iopub.execute_input":"2022-05-10T20:23:32.707624Z","iopub.status.idle":"2022-05-10T20:23:32.720518Z","shell.execute_reply.started":"2022-05-10T20:23:32.707597Z","shell.execute_reply":"2022-05-10T20:23:32.719380Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def init_layer(m):\n    torch.nn.init.xavier_normal_(m.weight, gain=torch.nn.init.calculate_gain('tanh'))\n    torch.nn.init.constant_(m.bias, 0)\n    return m\n\nclass Network(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.dropout = nn.Dropout(p=0.5)\n        self.tanh = nn.Tanh()\n        self.ln1 = init_layer(nn.Linear(6, 12))\n        self.ln2 = init_layer(nn.Linear(12, 12))\n        self.ln3 = init_layer(nn.Linear(12, 1))\n        self.sigmoid = nn.Sigmoid()\n        self.pr_model = TransformerModel(len(vocab_pr), 16, 4, 32, 3)\n        self.rt_model = TransformerModel(len(vocab_rt), 16, 4, 32, 3)\n        \n    def forward(self, x):\n        x = self.dropout(self.tanh(self.ln1(x)))\n        x = self.dropout(self.tanh(self.ln2(x)))\n        return self.sigmoid(self.ln3(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:32.721714Z","iopub.execute_input":"2022-05-10T20:23:32.722149Z","iopub.status.idle":"2022-05-10T20:23:32.733022Z","shell.execute_reply.started":"2022-05-10T20:23:32.722107Z","shell.execute_reply":"2022-05-10T20:23:32.732281Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"net = Network()\n\ncriterion=torch.nn.BCELoss()\n\noptimizer = torch.optim.Adam(net.parameters(), lr=0.003)\n\nnb_iterations = 100\n\nnet.train()\nfor j in range(nb_iterations):\n    correctly_predicted = 0\n    total_prediction = 0\n    training_loss = 0\n    src_mask = generate_square_subsequent_mask(32)\n    for batch_idx, data in enumerate(zip(loader_pr_train, loader_rt_train, loader_features_train)):\n        optimizer.zero_grad()\n        prs, rts, (num_features, label) = data\n        if rts.size(0) != 32:  # only on last batch\n            src_mask = src_mask[:rts.size(0), :rts.size(0)]\n        prs = net.pr_model(prs, src_mask)\n        rts = net.rt_model(rts, src_mask)\n        x = torch.hstack((num_features, prs, rts))\n        output = net(x)\n        loss = criterion(output.view(-1), label)\n        loss.backward()\n        optimizer.step()\n        training_loss += loss.item()\n        predicted = torch.ge(output, 0.5).view(-1)\n        correctly_predicted += torch.sum(label == predicted)\n        total_prediction += output.shape[0]\n    print(f'iter {j} training loss {training_loss} accuracy training {correctly_predicted / total_prediction}')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:23:32.734313Z","iopub.execute_input":"2022-05-10T20:23:32.734568Z","iopub.status.idle":"2022-05-10T20:26:10.220913Z","shell.execute_reply.started":"2022-05-10T20:23:32.734537Z","shell.execute_reply":"2022-05-10T20:26:10.219651Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"net.eval()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T20:26:10.223143Z","iopub.execute_input":"2022-05-10T20:26:10.223551Z","iopub.status.idle":"2022-05-10T20:26:10.233420Z","shell.execute_reply.started":"2022-05-10T20:26:10.223501Z","shell.execute_reply":"2022-05-10T20:26:10.232306Z"},"trusted":true},"execution_count":40,"outputs":[]}]}