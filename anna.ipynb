{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preliminaries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:10:09.544064Z","iopub.status.busy":"2022-05-10T11:10:09.543377Z","iopub.status.idle":"2022-05-10T11:13:42.403673Z","shell.execute_reply":"2022-05-10T11:13:42.402650Z","shell.execute_reply.started":"2022-05-10T11:10:09.544015Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils import data\n","import wandb\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","#wandb.init(project=\"HIV_kaggle\")"]},{"cell_type":"markdown","metadata":{},"source":["Parse and look at first 5 rows"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["infineon = True # laptop\n","hpc_cluster = False\n","\n","config = dict()\n","\n","if infineon:\n","    config['path_workspace'] = 'C:\\\\Users\\\\SafontAndreu\\\\Workspace\\\\Visual Studio Code\\\\ps_hiv\\\\'\n","    config['path_inputs'] = 'C:\\\\Users\\\\SafontAndreu\\\\'\n","    \n","else:\n","    config['path_workspace'] = 'C:\\\\Users\\\\soren\\\\Alpen-Adria Universit√§t Klagenfurt\\\\PhD - General\\\\Workspace\\\\Visual Studio Code\\\\'\n","    config['path_inputs'] = 'D:\\\\PhD\\\\'\n","\n","config['path_database'] = config.get('path_workspace') + 'data\\\\'\n","config['path_models'] = config.get('path_inputs') + 'Models\\\\'\n","config['path_results'] = config.get('path_inputs') + 'Results\\\\'\n","config['path_ontology'] = config.get('path_inputs') + 'Ontology\\\\'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:13:42.406280Z","iopub.status.busy":"2022-05-10T11:13:42.405902Z","iopub.status.idle":"2022-05-10T11:13:43.368004Z","shell.execute_reply":"2022-05-10T11:13:43.367271Z","shell.execute_reply.started":"2022-05-10T11:13:42.406248Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PatientID</th>\n","      <th>Resp</th>\n","      <th>PR Seq</th>\n","      <th>RT Seq</th>\n","      <th>VL-t0</th>\n","      <th>CD4-t0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...</td>\n","      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...</td>\n","      <td>4.3</td>\n","      <td>145</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...</td>\n","      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n","      <td>3.6</td>\n","      <td>224</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...</td>\n","      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n","      <td>3.2</td>\n","      <td>1017</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...</td>\n","      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n","      <td>5.7</td>\n","      <td>206</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...</td>\n","      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n","      <td>3.5</td>\n","      <td>572</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PatientID  Resp                                             PR Seq  \\\n","0          1     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...   \n","1          2     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...   \n","2          3     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...   \n","3          4     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...   \n","4          5     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...   \n","\n","                                              RT Seq  VL-t0  CD4-t0  \n","0  CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...    4.3     145  \n","1  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    3.6     224  \n","2  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    3.2    1017  \n","3  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    5.7     206  \n","4  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    3.5     572  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_data = df = pd.read_csv(config.get('path_database')+'training_data.csv', header=0, index_col=False, encoding='utf-8', low_memory=False)\n","test_data = df = pd.read_csv(config.get('path_database')+'test_data_mod.csv', header=0, index_col=False, encoding='utf-8', low_memory=False)\n","sol_data = df = pd.read_csv(config.get('path_database')+'hivprogression_solution.csv', header=0, index_col=False, encoding='utf-8', low_memory=False)\n","train_data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:13:43.369576Z","iopub.status.busy":"2022-05-10T11:13:43.369227Z","iopub.status.idle":"2022-05-10T11:13:44.271548Z","shell.execute_reply":"2022-05-10T11:13:44.270572Z","shell.execute_reply.started":"2022-05-10T11:13:43.369547Z"},"trusted":true},"outputs":[],"source":["n_train = train_data.shape[0]"]},{"cell_type":"markdown","metadata":{},"source":["We have to remove the first two columns"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:13:44.274531Z","iopub.status.busy":"2022-05-10T11:13:44.274285Z","iopub.status.idle":"2022-05-10T11:13:45.104694Z","shell.execute_reply":"2022-05-10T11:13:45.103813Z","shell.execute_reply.started":"2022-05-10T11:13:44.274504Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1000, 4)\n","(1000, 7)\n","<bound method NDFrame.head of                                                 PR Seq  \\\n","0    CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...   \n","1    CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...   \n","2    CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...   \n","3    CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...   \n","4    CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...   \n","..                                                 ...   \n","995                                                NaN   \n","996                                                NaN   \n","997                                                NaN   \n","998                                                NaN   \n","999                                                NaN   \n","\n","                                                RT Seq     VL-t0    CD4-t0  \\\n","0    CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...  0.004059 -0.679249   \n","1    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA... -0.989159 -0.280635   \n","2    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA... -1.556713  3.720642   \n","3    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...  1.990495 -0.371459   \n","4    CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA... -1.131048  1.475285   \n","..                                                 ...       ...       ...   \n","995  CCCATTAGTCCTATTGARACTGTACCAGTAMAATTAAAGCCAGGAA... -1.627657  0.375312   \n","996  CCCATYAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...  1.706718 -1.158595   \n","997  CCCATYAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA... -0.279718  0.450998   \n","998  CCTATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA... -1.315503 -0.770073   \n","999  CCTATTAGTCCTATTGAAACTGTACCTGTAAAATTAAAGCMAGGAA...  0.954710  1.465193   \n","\n","     PR SeqNan  RT SeqNan  Resp  \n","0        False      False     0  \n","1        False      False     0  \n","2        False      False     0  \n","3        False      False     0  \n","4        False      False     0  \n","..         ...        ...   ...  \n","995       True      False     0  \n","996       True      False     0  \n","997       True      False     0  \n","998       True      False     0  \n","999       True      False     0  \n","\n","[1000 rows x 7 columns]>\n"]}],"source":["all_features = train_data.iloc[:, 2:]\n","print(all_features.shape)\n","# one can assume if Seqs are not present it is a bad sign for survival\n","all_features[\"PR SeqNan\"] = all_features[\"PR Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\n","all_features[\"RT SeqNan\"] = all_features[\"RT Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\n","numeric_features = all_features.dtypes[(all_features.dtypes != 'object') & (all_features.dtypes != 'bool')].index\n","mean_numerical_features = all_features[numeric_features].mean()\n","std_numerical_features = all_features[numeric_features].std()\n","all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / x.std() + 1e-4)\n","vt_mean = all_features[\"VL-t0\"].mean()\n","cd4_mean = all_features[\"CD4-t0\"].mean()\n","all_features[\"VL-t0\"] = all_features[\"VL-t0\"].fillna(vt_mean)\n","all_features[\"CD4-t0\"] = all_features[\"CD4-t0\"].fillna(cd4_mean)\n","all_features.head()\n","\n","\n","all_features['Resp'] = train_data['Resp']\n","print(all_features.shape)\n","print(all_features.head)"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenize and Vocab"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:13:45.106531Z","iopub.status.busy":"2022-05-10T11:13:45.106195Z","iopub.status.idle":"2022-05-10T11:13:45.866642Z","shell.execute_reply":"2022-05-10T11:13:45.865787Z","shell.execute_reply.started":"2022-05-10T11:13:45.106489Z"},"trusted":true},"outputs":[],"source":["import collections\n","\n","def tokenize(seqs):\n","    return [tokenize_line(seq) for seq in seqs]\n","\n","def tokenize_line(seq):\n","    if not pd.isna(seq):\n","        return list(seq)\n","    return []\n","\n","class Vocab:\n","    def __init__(self, tokens):\n","        counter = count_corpus(tokens)\n","        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n","                                   reverse=True)\n","        self.idx_to_token = ['<unk>']\n","        self.token_to_idx = {token: idx\n","                             for idx, token in enumerate(self.idx_to_token)}\n","        for token, freq in self._token_freqs:\n","            if token not in self.token_to_idx:\n","                self.idx_to_token.append(token)\n","                self.token_to_idx[token] = len(self.idx_to_token) - 1\n","\n","    def __len__(self):\n","        return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","        if not isinstance(tokens, (list, tuple)):\n","            return self.token_to_idx.get(tokens, self.unk)\n","        return [self.__getitem__(token) for token in tokens]\n","\n","    def to_tokens(self, indices):\n","        if not isinstance(indices, (list, tuple)):\n","            return self.idx_to_token[indices]\n","        return [self.idx_to_token[index] for index in indices]\n","\n","    @property\n","    def unk(self): \n","        return 0\n","\n","    @property\n","    def token_freqs(self):\n","        return self._token_freqs\n","\n","def count_corpus(tokens):\n","    if len(tokens) == 0 or isinstance(tokens[0], list):\n","        tokens = [token for line in tokens for token in line]\n","    return collections.Counter(tokens)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["#X_name = 'PR Seq'\n","X_name = 'RT Seq'\n","\n","y_name = 'Resp'"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:13:46.808121Z","iopub.status.busy":"2022-05-10T11:13:46.807253Z","iopub.status.idle":"2022-05-10T11:13:47.647763Z","shell.execute_reply":"2022-05-10T11:13:47.646909Z","shell.execute_reply.started":"2022-05-10T11:13:46.808045Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[('<unk>', 0),\n"," ('A', 1),\n"," ('T', 2),\n"," ('G', 3),\n"," ('C', 4),\n"," ('R', 5),\n"," ('Y', 6),\n"," ('M', 7),\n"," ('W', 8),\n"," ('K', 9),\n"," ('N', 10),\n"," ('S', 11),\n"," ('H', 12),\n"," ('D', 13),\n"," ('V', 14),\n"," ('B', 15)]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokens_rt = tokenize(all_features[X_name].values)\n","vocab_rt = Vocab(tokens_rt)\n","list(vocab_rt.token_to_idx.items())"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-05-10T11:13:47.649559Z","iopub.status.busy":"2022-05-10T11:13:47.648879Z","iopub.status.idle":"2022-05-10T11:13:49.335091Z","shell.execute_reply":"2022-05-10T11:13:49.334255Z","shell.execute_reply.started":"2022-05-10T11:13:47.649523Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","1      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","2      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","3      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","4      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","                             ...                        \n","995    [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","996    [4, 4, 4, 1, 2, 6, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","997    [4, 4, 4, 1, 2, 6, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","998    [4, 4, 2, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","999    [4, 4, 2, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","Name: RT Seq, Length: 1000, dtype: object"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["all_features[X_name] = all_features[X_name].apply(lambda x: vocab_rt[tokenize_line(x)])\n","all_features[X_name]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique nucleotides in PR Sequence =  ABCDGHKMNRSTVWY\n","Unique nucleotides in RT Sequence =  ABCDGHKMNRSTVWY\n"]}],"source":["seq_pr = train_data['PR Seq']\n","\n","seq_pr_unique = ''\n","for ele in seq_pr:\n","    if isinstance(ele, str):\n","        seq_pr_unique += ''.join(set(ele))\n","seq_pr_unique = ''.join(set(seq_pr_unique))\n","seq_pr_unique = ''.join(sorted(seq_pr_unique))\n","print('Unique nucleotides in PR Sequence = ', seq_pr_unique)\n","\n","\n","\n","seq_rt = train_data['RT Seq']\n","\n","seq_rt_unique = ''\n","for ele in seq_rt:\n","    if isinstance(ele, str):\n","        seq_rt_unique += ''.join(set(ele))\n","seq_rt_unique = ''.join(set(seq_rt_unique))\n","seq_rt_unique = ''.join(sorted(seq_rt_unique))\n","print('Unique nucleotides in RT Sequence = ', seq_rt_unique)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['PR Seq', 'RT Seq', 'VL-t0', 'CD4-t0', 'PR SeqNan', 'RT SeqNan',\n","       'Resp'],\n","      dtype='object')\n"]}],"source":["print(all_features.columns)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["X = all_features[X_name].values\n","y = all_features[y_name].values\n","\n","x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)\n","\n","if X_name == 'PR Seq':\n","    vocab = seq_pr_unique\n","if X_name == 'RT Seq':\n","    vocab = seq_rt_unique"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 1005, 15)          240       \n","                                                                 \n"," lstm (LSTM)                 (None, 10)                1040      \n","                                                                 \n"," dense (Dense)               (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 1,291\n","Trainable params: 1,291\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 600 samples, validate on 150 samples\n","Epoch 1/5\n","600/600 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4917"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\SafontAndreu\\Workspace\\Visual Studio Code\\.venv\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"name":"stdout","output_type":"stream","text":["600/600 [==============================] - 9s 15ms/sample - loss: 0.6931 - accuracy: 0.4917 - val_loss: 0.6887 - val_accuracy: 0.7933\n","Epoch 2/5\n","600/600 [==============================] - 8s 14ms/sample - loss: 0.6842 - accuracy: 0.7983 - val_loss: 0.6798 - val_accuracy: 0.7933\n","Epoch 3/5\n","600/600 [==============================] - 8s 13ms/sample - loss: 0.6746 - accuracy: 0.7983 - val_loss: 0.6694 - val_accuracy: 0.7933\n","Epoch 4/5\n","600/600 [==============================] - 7s 12ms/sample - loss: 0.6631 - accuracy: 0.7983 - val_loss: 0.6567 - val_accuracy: 0.7933\n","Epoch 5/5\n","600/600 [==============================] - 7s 12ms/sample - loss: 0.6489 - accuracy: 0.7983 - val_loss: 0.6401 - val_accuracy: 0.7933\n","Validation results - Loss: 0.6418432645797729 - Accuracy: 78.39999794960022%\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding, Dense, LSTM\n","from keras.losses import BinaryCrossentropy\n","from keras.models import Sequential\n","from keras.optimizers import adam_v2\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# Model configuration\n","additional_metrics = ['accuracy']\n","batch_size = 32\n","embedding_output_dims = 15\n","loss_function = BinaryCrossentropy()\n","max_sequence_length = 1005\n","num_distinct_words = len(vocab)+1\n","epochs = 5\n","lr = 2e-4\n","optimizer = adam_v2.Adam(learning_rate=lr, decay=lr/epochs)\n","validation_split = 0.20\n","verbosity_mode = 1\n","\n","# Disable eager execution\n","tf.compat.v1.disable_eager_execution()\n","\n","# Pad all sequences\n","padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n","padded_inputs_valid = pad_sequences(x_valid, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n","\n","# Define the Keras model\n","model = Sequential()\n","model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n","model.add(LSTM(10))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n","\n","# Give a summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(padded_inputs, y_train, batch_size=batch_size, epochs=epochs, verbose=verbosity_mode, validation_split=validation_split)\n","\n","# Test the model after training\n","valid_results = model.evaluate(padded_inputs_valid, y_valid, verbose=False)\n","print(f'Validation results - Loss: {valid_results[0]} - Accuracy: {100*valid_results[1]}%')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(692, 4)\n","(692, 7)\n"]}],"source":["all_features_test = test_data.iloc[:, 2:]\n","print(all_features_test.shape)\n","# one can assume if Seqs are not present it is a bad sign for survival\n","all_features_test[\"PR SeqNan\"] = all_features_test[\"PR Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\n","all_features_test[\"RT SeqNan\"] = all_features_test[\"RT Seq\"].apply(lambda x: pd.isna(x)).astype(bool)\n","numeric_features_test = all_features_test.dtypes[(all_features_test.dtypes != 'object') & (all_features_test.dtypes != 'bool')].index\n","mean_numerical_features_test = all_features_test[numeric_features_test].mean()\n","std_numerical_features_test = all_features_test[numeric_features_test].std()\n","all_features_test[numeric_features_test] = all_features_test[numeric_features_test].apply(lambda x: (x - x.mean()) / x.std() + 1e-4)\n","vt_mean_test = all_features_test[\"VL-t0\"].mean()\n","cd4_mean_test = all_features_test[\"CD4-t0\"].mean()\n","all_features_test[\"VL-t0\"] = all_features_test[\"VL-t0\"].fillna(vt_mean_test)\n","all_features_test[\"CD4-t0\"] = all_features_test[\"CD4-t0\"].fillna(cd4_mean_test)\n","all_features_test.head()\n","\n","\n","all_features_test['Resp'] = test_data['Resp']\n","print(all_features_test.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["[('<unk>', 0),\n"," ('A', 1),\n"," ('T', 2),\n"," ('G', 3),\n"," ('C', 4),\n"," ('R', 5),\n"," ('Y', 6),\n"," ('N', 7),\n"," ('M', 8),\n"," ('W', 9),\n"," ('K', 10),\n"," ('S', 11),\n"," ('D', 12),\n"," ('V', 13),\n"," ('H', 14),\n"," ('B', 15)]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tokens_pr_test = tokenize(all_features_test[X_name].values)\n","vocab_pr_test = Vocab(tokens_pr_test)\n","list(vocab_pr_test.token_to_idx.items())"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["0      [4, 4, 2, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","1      [4, 4, 4, 1, 2, 4, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","2      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","3      [4, 4, 2, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","4      [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","                             ...                        \n","687    [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","688    [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","689    [4, 4, 2, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","690    [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","691    [4, 4, 4, 1, 2, 2, 1, 3, 2, 4, 4, 2, 1, 2, 2, ...\n","Name: RT Seq, Length: 692, dtype: object"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["all_features_test[X_name] = all_features_test[X_name].apply(lambda x: vocab_pr_test[tokenize_line(x)])\n","all_features_test[X_name]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test results - Loss: 0.6980073717288199 - Accuracy: 50.0%\n"]}],"source":["x_test = all_features_test[X_name]\n","y_test = all_features_test[y_name]\n","\n","padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n","\n","test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)\n","print(f'Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%')"]}],"metadata":{"interpreter":{"hash":"42e89516d249f0b2da6278eedde058b7558b40d85564a4e7660d0a7c55b09129"},"kernelspec":{"display_name":"Python 3.8.10 ('.venv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
